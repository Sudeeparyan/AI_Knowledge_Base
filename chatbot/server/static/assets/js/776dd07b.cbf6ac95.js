"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[5820],{1282:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>t,default:()=>u,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var o=r(74848),s=r(28453);const i={},t=void 0,l={id:"AI360/FineTuning/Libraries and Tools/Platform and tools",title:"Platform and tools",description:"The platforms give free resource for fine tuning",source:"@site/docs/AI360/FineTuning/Libraries and Tools/Platform and tools.md",sourceDirName:"AI360/FineTuning/Libraries and Tools",slug:"/AI360/FineTuning/Libraries and Tools/Platform and tools",permalink:"/docs/AI360/FineTuning/Libraries and Tools/Platform and tools",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"AI360Sidebar",previous:{title:"Important Libraries",permalink:"/docs/AI360/FineTuning/Libraries and Tools/Important Libraries"},next:{title:"Open AI models - Fine tuning",permalink:"/docs/category/open-ai-models---fine-tuning"}},a={},c=[{value:"The platforms give free resource for fine tuning",id:"the-platforms-give-free-resource-for-fine-tuning",level:2},{value:"<strong>More tools</strong>",id:"more-tools",level:2},{value:"<strong>Popular Resources for Fine Tuning</strong>",id:"popular-resources-for-fine-tuning",level:2}];function d(e){const n={a:"a",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"the-platforms-give-free-resource-for-fine-tuning",children:"The platforms give free resource for fine tuning"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Colab gives free GPU - 16GB"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Kaggle gives free GPU - GPU T4 x2, P100, TPU VM v3-8"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"more-tools",children:(0,o.jsx)(n.strong,{children:"More tools"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"VextApp: Create custom LLMs with no, works code based on connectors."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"GradientAI: Used to train and deploy open source models."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"popular-resources-for-fine-tuning",children:(0,o.jsx)(n.strong,{children:"Popular Resources for Fine Tuning"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://github.com/Curated-Awesome-Lists/awesome-llms-fine-tuning?tab=readme-ov-file",children:"Awesome LLMs Fine Tuning"}),"  - Many useful resources for fine tuning"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://github.com/hiyouga/LLaMA-Factory",children:"LLaMA Factory"}),"  - To fine tunemost of the open source models"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://medium.com/neo4j/knowledge-graphs-llms-fine-tuning-vs-retrieval-augmented-generation-30e875d63a35",children:"Fine Tuning vs Retrieval-Augmented Generation"}),"  - This article gives multiple projects on fine-tuning. In RAG, knowledge graph helps multi-hop question-answering better."]}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>l});var o=r(96540);const s={},i=o.createContext(s);function t(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);
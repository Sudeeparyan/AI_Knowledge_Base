"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[6424],{10294:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var t=s(74848),r=s(28453);const i={},a=void 0,o={id:"RAG360/Data Ingestion/Embedding/Sparse Vector/BM25",title:"BM25",description:"Creating Sparse Vectors with BM25",source:"@site/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/BM25.md",sourceDirName:"RAG360/Data Ingestion/Embedding/Sparse Vector",slug:"/RAG360/Data Ingestion/Embedding/Sparse Vector/BM25",permalink:"/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/BM25",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"ragSidebar",previous:{title:"Overview",permalink:"/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/Overview"},next:{title:"TF-TDF",permalink:"/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/TF-TDF"}},c={},l=[{value:"Creating Sparse Vectors with BM25",id:"creating-sparse-vectors-with-bm25",level:2},{value:"Introduction to BM25",id:"introduction-to-bm25",level:3},{value:"Why BM25 Works: Term Weighting with Saturation",id:"why-bm25-works-term-weighting-with-saturation",level:3},{value:"Key Concepts in BM25",id:"key-concepts-in-bm25",level:3},{value:"Calculating BM25 Score",id:"calculating-bm25-score",level:3},{value:"Creating the Sparse Vector",id:"creating-the-sparse-vector",level:2},{value:"Sparse Vector Representation",id:"sparse-vector-representation",level:3},{value:"Sparsity",id:"sparsity",level:3},{value:"Example",id:"example",level:3},{value:"Technical Details",id:"technical-details",level:2},{value:"Sparse Representation",id:"sparse-representation",level:3},{value:"Dimensionality",id:"dimensionality",level:3},{value:"Memory Usage Example",id:"memory-usage-example",level:3},{value:"Advantages and Disadvantages of BM25",id:"advantages-and-disadvantages-of-bm25",level:2},{value:"<strong>Advantages:</strong>",id:"advantages",level:4},{value:"<strong>Disadvantages:</strong>",id:"disadvantages",level:4},{value:"Known Limitations of BM25",id:"known-limitations-of-bm25",level:2}];function d(e){const n={h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"creating-sparse-vectors-with-bm25",children:"Creating Sparse Vectors with BM25"}),"\n",(0,t.jsx)(n.h3,{id:"introduction-to-bm25",children:"Introduction to BM25"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"BM25 (Best Matching 25)"})," is a ranking function used by search engines to\r\nevaluate how relevant a document is to a given query."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It is an extension of the classic TF-IDF model and is part of the family of\r\nprobabilistic information retrieval models."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"BM25 is particularly effective in ranking documents based on their relevance\r\nto a query, making it a widely used technique in information retrieval\r\nsystems."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Weaviate uses BM25 algorithm to create sparse vectors whereas Qdrant uses\r\nlight weight BM25 model to create sparse vectors"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"why-bm25-works-term-weighting-with-saturation",children:"Why BM25 Works: Term Weighting with Saturation"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"BM25 can be considered an enhancement of TF-IDF due to two key factors: 1. It\r\ntakes into account the document length. 2. It incorporates the concept of a\r\nkeyword saturation term."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It emphasizes terms that are frequent in a document but rare across the\r\ncorpus, similar to TF-IDF."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"However, BM25 adds a non-linear saturation function that prevents the term\r\nfrequency from growing too large, ensuring that very frequent terms do not\r\ndisproportionately influence the ranking."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"key-concepts-in-bm25",children:"Key Concepts in BM25"}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Term Frequency (TF)"})}),(0,t.jsx)("td",{children:"Measures how often a term appears in a document. BM25 applies a logarithmic scaling to this frequency to prevent very frequent terms from dominating the score."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Inverse Document Frequency (IDF)"})}),(0,t.jsx)("td",{children:"Measures how unique a term is across all documents in the corpus. BM25 uses a slightly modified IDF calculation that adds a constant to the denominator, avoiding extreme values."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Document Length Normalization"})}),(0,t.jsx)("td",{children:"BM25 normalizes term frequency by the length of the document, ensuring that longer documents are not unfairly penalized or favored."})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"calculating-bm25-score",children:"Calculating BM25 Score"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The BM25 score is calculated by combining term frequency, inverse document\r\nfrequency, and document length normalization."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The formula for BM25 is as follows:"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"image.png",src:s(54667).A+"",width:"903",height:"682"})}),"\n",(0,t.jsx)(n.h2,{id:"creating-the-sparse-vector",children:"Creating the Sparse Vector"}),"\n",(0,t.jsx)(n.h3,{id:"sparse-vector-representation",children:"Sparse Vector Representation"}),"\n",(0,t.jsx)(n.p,{children:"For each document, BM25 creates a sparse vector where each dimension corresponds\r\nto a term from the vocabulary, and the value at each dimension is the BM25 score\r\nfor that term in that document."}),"\n",(0,t.jsx)(n.h3,{id:"sparsity",children:"Sparsity"}),"\n",(0,t.jsx)(n.p,{children:"As with TF-IDF, BM25 also produces sparse vectors because many terms in the\r\nvocabulary do not appear in any given document, leading to many zero entries in\r\nthe vector."}),"\n",(0,t.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The sparse BM25 vector for Document 1 might look like this (with non-zero\r\nelements shown):"}),"\n",(0,t.jsx)(n.p,{children:"[ [0, 0, 1.8, 2.2, 0, 0, 0, 0, 0, 0] ]"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"This vector indicates that only a few terms from the vocabulary have\r\nnon-zero BM25 scores in Document 1."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"technical-details",children:"Technical Details"}),"\n",(0,t.jsx)(n.h3,{id:"sparse-representation",children:"Sparse Representation"}),"\n",(0,t.jsx)(n.p,{children:"BM25, like TF-IDF, produces sparse vectors, but the weighting of terms is more\r\nnuanced due to the saturation and normalization effects. This results in more\r\nbalanced representations, especially for longer documents."}),"\n",(0,t.jsx)(n.h3,{id:"dimensionality",children:"Dimensionality"}),"\n",(0,t.jsx)(n.p,{children:"The dimensionality of a BM25 vector depends on the number of unique terms in the\r\ncorpus. However, the sparsity of the vector ensures that only a few terms have\r\nnon-zero weights, making it memory efficient."}),"\n",(0,t.jsx)(n.h3,{id:"memory-usage-example",children:"Memory Usage Example"}),"\n",(0,t.jsx)(n.p,{children:"For a corpus with 1 million documents and 10,000 unique terms:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dense Representation"}),": Storing full vectors for each document would require 10 billion floats."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sparse Representation"}),": BM25\u2019s sparse vectors require significantly less storage, as only non-zero entries (i.e., terms that actually appear in the document) are stored."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"advantages-and-disadvantages-of-bm25",children:"Advantages and Disadvantages of BM25"}),"\n",(0,t.jsx)(n.h4,{id:"advantages",children:(0,t.jsx)(n.strong,{children:"Advantages:"})}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Relevance"})}),(0,t.jsx)("td",{children:"BM25 is highly effective in ranking documents by relevance, outperforming simpler models like TF-IDF in many cases."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Simplicity"})}),(0,t.jsx)("td",{children:"Despite its enhancements, BM25 remains relatively simple to implement and interpret."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Efficiency"})}),(0,t.jsx)("td",{children:"Sparse vectors reduce memory usage and computational load, making BM25 suitable for large-scale retrieval tasks."})]})]})]}),"\n",(0,t.jsx)(n.h4,{id:"disadvantages",children:(0,t.jsx)(n.strong,{children:"Disadvantages:"})}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Hyperparameter Sensitivity"})}),(0,t.jsx)("td",{children:"The effectiveness of BM25 can be sensitive to the choice of hyperparameters ( k_1 ) and ( b )."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Vocabulary Size"})}),(0,t.jsx)("td",{children:"The dimensionality of BM25 vectors grows with the size of the vocabulary, which can become challenging for very large corpora."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Context Ignorance"})}),(0,t.jsx)("td",{children:"Like TF-IDF, BM25 does not capture the semantic meaning of words or their context within a document."})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"known-limitations-of-bm25",children:"Known Limitations of BM25"}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Context Sensitivity"})}),(0,t.jsx)("td",{children:"BM25, like TF-IDF, does not consider the context in which a term appears, which can lead to misinterpretations in cases where context is crucial."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Synonym Handling"})}),(0,t.jsx)("td",{children:"BM25 treats synonyms as different terms, potentially leading to redundant features and diluting the importance of key concepts."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Scalability Issues"})}),(0,t.jsx)("td",{children:"While BM25\u2019s sparse vectors are memory-efficient, the increasing dimensionality with larger corpora can pose scalability challenges, particularly in terms of computational resources."})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},54667:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/BM25-31e184a56591523479f7d96970c0c355.png"},28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var t=s(96540);const r={},i=t.createContext(r);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);
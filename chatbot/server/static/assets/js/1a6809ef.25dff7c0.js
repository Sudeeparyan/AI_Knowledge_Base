"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[8447],{74184:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var s=t(74848),a=t(28453);const i={},r=void 0,o={id:"AI360/Fundamentals/GenAI",title:"GenAI",description:"Traditional model",source:"@site/docs/AI360/Fundamentals/GenAI.md",sourceDirName:"AI360/Fundamentals",slug:"/AI360/Fundamentals/GenAI",permalink:"/docs/AI360/Fundamentals/GenAI",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"AI360Sidebar",previous:{title:"Basics",permalink:"/docs/AI360/Fundamentals/Basics"},next:{title:"Transformer",permalink:"/docs/AI360/Fundamentals/Transformer"}},l={},d=[{value:"Traditional model",id:"traditional-model",level:2},{value:"Generative model",id:"generative-model",level:2},{value:"What is GEN AI?",id:"what-is-gen-ai",level:2},{value:"LLM",id:"llm",level:2}];function c(e){const n={a:"a",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"traditional-model",children:"Traditional model"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:t(53761).A+"",width:"985",height:"577"})}),"\n",(0,s.jsx)(n.h2,{id:"generative-model",children:"Generative model"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:t(9402).A+"",width:"922",height:"597"})}),"\n",(0,s.jsx)(n.h2,{id:"what-is-gen-ai",children:"What is GEN AI?"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Generative AI refers to any artificial intelligence system capable of creating new content, such as text, images, music, or even code, based on the data it was trained on."}),"\n",(0,s.jsx)(n.li,{children:"Different Gen AI models are"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:t(91040).A+"",width:"266",height:"290"})}),"\n",(0,s.jsx)(n.h2,{id:"llm",children:"LLM"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["LLM's are ",(0,s.jsx)(n.strong,{children:"Large"}),", ",(0,s.jsx)(n.strong,{children:"general-purpose language"})," models can be pre-trained and then fine-tuned for specific purposes."]}),"\n",(0,s.jsx)(n.li,{children:'Imagine you are training a dog, often you train your dog on the basic commands like "sit","come", "down", "stay". These are some general commands that the dog trained with, for normal use-case.'}),"\n",(0,s.jsx)(n.li,{children:"However, If you need a special service dog such as police dog, guide dog,  hunting dog, you need to give special set of trainings to specialize in the respective tasks."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:t(77078).A+"",width:"834",height:"421"})}),"\n",(0,s.jsxs)(n.ol,{start:"4",children:["\n",(0,s.jsx)(n.li,{children:"Similarly, Large language models are trained to solve the common problems like text classification, question answering, document summarization,text generation etc.,"}),"\n",(0,s.jsx)(n.li,{children:"Then these model can be fine-tuned to solve specific problems in the different fields like retail, finance and entertainment, etc..,"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:t(58701).A+"",width:"921",height:"381"})}),"\n",(0,s.jsxs)(n.ol,{start:"6",children:["\n",(0,s.jsx)(n.li,{children:"Large Language Models are designed to understand and generate human-like text based on massive amounts of data."}),"\n",(0,s.jsx)(n.li,{children:"These models are trained on vast datasets that include text from books, websites, articles, and other sources to learn the structure and patterns of language."}),"\n",(0,s.jsx)(n.li,{children:"With their ability to process and generate coherent, contextually relevant text, LLMs have become prominent tools for tasks like text completion, answering questions, translation, summarization, and even conversation."}),"\n",(0,s.jsxs)(n.li,{children:["The most widely know LLMs are the GPT (Generative Pre-trained Transformer) series, developed by OpenAI, and BERT (Bidirectional Encoder Representations from Transformers), produced by Google. These models use the Transformer architecture, a type of neural network introduced in the paper\r\n",(0,s.jsx)(n.a,{href:"https://research.google/pubs/attention-is-all-you-need/",children:"\u201cAttention Is All You Need\u201d"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},9402:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/genai-0024fdbe3f95b416f30cb491f3029bc2.png"},91040:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/genaimodels-9038e8591b3cd89cc7993f3a8e05f974.png"},77078:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/llm1-50b3f7c722bf6dc5ba3c9064c56bdcd9.png"},58701:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/llm2-56fbeeb90a386d12a189f3d4c023907a.png"},53761:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/traditional-4dd2398088ce4cd485dc41d6a71ade59.png"},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(96540);const a={},i=s.createContext(a);function r(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);
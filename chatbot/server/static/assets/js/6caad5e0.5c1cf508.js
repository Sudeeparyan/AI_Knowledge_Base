"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[5166],{20829:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var t=s(74848),r=s(28453);const i={},d=void 0,a={id:"RAG360/Data Ingestion/Embedding/Sparse Vector/Splade",title:"Splade",description:"An Efficient Way to Make Sparse Vectors",source:"@site/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/Splade.md",sourceDirName:"RAG360/Data Ingestion/Embedding/Sparse Vector",slug:"/RAG360/Data Ingestion/Embedding/Sparse Vector/Splade",permalink:"/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/Splade",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"ragSidebar",previous:{title:"TF-TDF",permalink:"/docs/RAG360/Data Ingestion/Embedding/Sparse Vector/TF-TDF"},next:{title:"Dense Vector",permalink:"/docs/category/dense-vector"}},o={},l=[{value:"An Efficient Way to Make Sparse Vectors",id:"an-efficient-way-to-make-sparse-vectors",level:3},{value:"How SPLADE Works: Term Expansion",id:"how-splade-works-term-expansion",level:3},{value:"Technical Details",id:"technical-details",level:3},{value:"Memory Usage Example",id:"memory-usage-example",level:4},{value:"How SPLADE Works: Leveraging BERT",id:"how-splade-works-leveraging-bert",level:3},{value:"Advantages and Disadvantages of SPLADE",id:"advantages-and-disadvantages-of-splade",level:3},{value:"<strong>Advantages</strong>",id:"advantages",level:4},{value:"<strong>Disadvantages</strong>",id:"disadvantages",level:4},{value:"Known Limitations of SPLADE",id:"known-limitations-of-splade",level:3},{value:"Reference",id:"reference",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h3:"h3",h4:"h4",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h3,{id:"an-efficient-way-to-make-sparse-vectors",children:"An Efficient Way to Make Sparse Vectors"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"SPLADE (Sparse LAttice Distance Embedding)"})," is a model designed to create\nsuch sparse vectors for text data."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"SPLADE is more a class of models rather than a single model."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"These models are part of the family of dense-to-sparse models that bridge the\ngap between dense embeddings and sparse retrieval techniques."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"They aim to leverage the strengths of both dense representations (like those\nproduced by Transformer models) and sparse, high-dimensional representations\nused in traditional retrieval systems."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Depending on the regularization magnitude, different models can be\nobtained\u2014from very sparse to models doing intense query/document\nexpansion\u2014with varying properties and performance."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"how-splade-works-term-expansion",children:"How SPLADE Works: Term Expansion"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"A key component of SPLADE is term expansion."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"For instance,"}),' given a query like "solar energy advantages," SPLADE might\nexpand it to include terms like "',(0,t.jsx)(n.code,{children:"renewable"}),'," "',(0,t.jsx)(n.code,{children:"sustainable"}),'," and\n"',(0,t.jsx)(n.code,{children:"photovoltaic"}),'," which are contextually relevant but not explicitly\nmentioned.']}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"This ability to expand queries and documents to include other relevant terms\ngives SPLADE a crucial advantage over other sparse methods that only include\nexact words while missing contextually relevant ones."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"In a TF-IDF, we\u2019d assign weights only to these tokens or words. In SPLADE, we assign weights to all the tokens in the vocabulary in which the model is trained."})}),"\n",(0,t.jsx)(n.h3,{id:"technical-details",children:"Technical Details"}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Sparsity via Regularization"})}),(0,t.jsx)("td",{children:"Controls the number of tokens (BERT wordpieces) used to represent each document. More tokens make the vectors denser."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Token Representation"})}),(0,t.jsx)("td",{children:"Typically between 20 to 200 tokens per document. For reference, the dense BERT vector is 768 dimensions, OpenAI Embedding is 1536 dimensions, and the sparse vector is 30 dimensions."})]})]})]}),"\n",(0,t.jsx)(n.h4,{id:"memory-usage-example",children:"Memory Usage Example"}),"\n",(0,t.jsxs)(n.p,{children:["For a 1M document corpus: 1. ",(0,t.jsx)(n.strong,{children:"Dense BERT Vector"}),": 768M floats 2. ",(0,t.jsx)(n.strong,{children:"OpenAI\nEmbedding"}),": 1.536B floats 3. ",(0,t.jsx)(n.strong,{children:"Sparse Vector"}),": Maximum of 100M integers + 100M\nfloats"]}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Vector Type"}),(0,t.jsx)(n.th,{children:"Memory (GB)"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Dense BERT Vector"}),(0,t.jsx)(n.td,{children:"6.144"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"OpenAI Embedding"}),(0,t.jsx)(n.td,{children:"12.288"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Sparse Vector"}),(0,t.jsx)(n.td,{children:"1.12"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"how-splade-works-leveraging-bert",children:"How SPLADE Works: Leveraging BERT"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"SPLADE uses a transformer architecture to generate sparse representations of\ndocuments and queries."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The output logits from the transformer backbone are used to build sparse\nvectors, emphasizing terms that are:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Contextually Relevant"}),": Terms that represent a document well."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Discriminative Across Documents"}),": Terms that a document has, and others don\u2019t."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"These token-level distributions are transformed into token-level importance\nscores in SPLADE, guiding the model to allocate more weight to significant\nterms."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"advantages-and-disadvantages-of-splade",children:"Advantages and Disadvantages of SPLADE"}),"\n",(0,t.jsx)(n.h4,{id:"advantages",children:(0,t.jsx)(n.strong,{children:"Advantages"})}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Keyword Search"})}),(0,t.jsx)("td",{children:"If we use only Keyword search, then SPLADE is recommended."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Memory Efficiency"})}),(0,t.jsx)("td",{children:"Sparse vectors significantly reduce memory usage."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Performance"})}),(0,t.jsx)("td",{children:"High retrieval effectiveness by expanding relevant terms."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Flexibility"})}),(0,t.jsx)("td",{children:"Tunable regularization allows for different model properties."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Interpretability"})}),(0,t.jsx)("td",{children:"Provides insights into why a document is relevant to a query."})]})]})]}),"\n",(0,t.jsx)(n.h4,{id:"disadvantages",children:(0,t.jsx)(n.strong,{children:"Disadvantages"})}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Sparse Vectors"})}),(0,t.jsx)("td",{children:"To create sparse vectors with SPLADE, we need GPU to do it faster."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Pooling Strategy Sensitivity"})}),(0,t.jsx)("td",{children:"Performance is sensitive to the choice of pooling strategy."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Query Encoder Dependency"})}),(0,t.jsx)("td",{children:"Efficiency can be affected by the necessity of a query encoder."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Embedding Time"})}),(0,t.jsx)("td",{children:"The time required to generate embeddings with SPLADE models depends on the hardware used. It is recommended to use a GPU for faster embedding creation."})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"known-limitations-of-splade",children:"Known Limitations of SPLADE"}),"\n",(0,t.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Factors"}),(0,t.jsx)("th",{children:"Reason"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Pooling Strategy"})}),(0,t.jsx)("td",{children:"The switch to max pooling improved performance but indicates a potential limitation in the baseline SPLADE pooling method."})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)("span",{class:"custom-header",children:"Document and Query Encoder"})}),(0,t.jsx)("td",{children:"Using a document encoder with max pooling but no query encoder achieves similar performance, suggesting a limitation in the necessity of a query encoder."})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"reference",children:"Reference"}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsx)(n.mdxAdmonitionTitle,{}),(0,t.jsxs)(n.p,{children:["Learn more about ",(0,t.jsx)(n.a,{href:"https://qdrant.tech/articles/sparse-vectors/",children:"Sparse Vector"})]})]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>d,x:()=>a});var t=s(96540);const r={},i=t.createContext(r);function d(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);
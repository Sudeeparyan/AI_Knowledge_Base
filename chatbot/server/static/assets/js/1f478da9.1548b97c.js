"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[8595],{18984:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var t=i(74848),s=i(28453);const a={},r="Steps in Finetuning",o={id:"AI360/FineTuning/Fine Tuning/Steps",title:"Steps in Finetuning",description:"steps in fine tune",source:"@site/docs/AI360/FineTuning/Fine Tuning/Steps.md",sourceDirName:"AI360/FineTuning/Fine Tuning",slug:"/AI360/FineTuning/Fine Tuning/Steps",permalink:"/docs/AI360/FineTuning/Fine Tuning/Steps",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"AI360Sidebar",previous:{title:"Methods of fine tuning",permalink:"/docs/AI360/FineTuning/Fine Tuning/methods"},next:{title:"When to use",permalink:"/docs/AI360/FineTuning/Fine Tuning/When to use"}},d={},l=[];function c(e){const n={h1:"h1",header:"header",img:"img",li:"li",ol:"ol",p:"p",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"steps-in-finetuning",children:"Steps in Finetuning"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"steps in fine tune",src:i(33042).A+"",width:"601",height:"459"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Step 1: Pre-training dataset"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"The pre-training dataset forms the backbone of the model\u2019s initial learning. This dataset is large, diverse, and designed to help the model grasp language patterns, grammar, and general knowledge. Typically, it includes a vast amount of text from books, websites, and articles. The aim at this stage is to expose the model to as much data as possible"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Step 2: Base LLM"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"The base LLM (Large Language Model) is the result of the initial pre-training. This is a general-purpose model that has learned to predict words, generate coherent text, and understand broad topics. At this stage, the model is versatile but lacks expertise in any specific domain."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Step 3: Domain Specific Knowledge"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"The next step involves introducing domain-specific knowledge. This knowledge is tailored to the particular area in which the model needs to perform. Whether it's legal, medical, or technical fields, this step ensures the model becomes familiar with the unique vocabulary, terminology, and context of the targeted domain. This specialized data is essential for preparing the model to handle more complex or niche tasks effectively."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Step 4: ETL Pipeline"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"In this step, the domain-specific data is collected, cleaned, and processed before it is used for fine-tuning. The extraction phase involves gathering relevant information, transforming it ensures that the data is in the correct format, and loading means it is fed into the model. A well-structured ETL pipeline ensures that the data used in fine-tuning is high-quality, consistent, and ready for training."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Step 5: Fine Tuning"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"During fine-tuning, the base model is trained on the domain-specific data. This process involves adjusting the model\u2019s parameters so it becomes better suited for tasks in the particular domain. Fine-tuning is a careful process that requires monitoring the model\u2019s performance to ensure that it is learning from the new data without forgetting the general knowledge it gained during pre-training. This step transforms the general-purpose model into one that can perform specialized tasks more effectively."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Step 6: Fine Tuned LLM"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"This model retains the broad knowledge it gained during pre-training but is now enhanced with domain-specific expertise. The fine-tuned model can deliver more accurate, context-aware results and is better suited for real-world applications within the target domain."}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},33042:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/fine-tune-steps-aab022242612ad727a1e77dd5a2a3345.jpeg"},28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var t=i(96540);const s={},a=t.createContext(s);function r(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);
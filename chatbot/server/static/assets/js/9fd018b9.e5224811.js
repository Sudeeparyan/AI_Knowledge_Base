"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[122],{93435:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var s=i(74848),t=i(28453);const r={},a=void 0,o={id:"RAG360/Types of RAG/Naive RAG",title:"Naive RAG",description:"1. Naive RAG (Retrieval Augmented Generation) represents the earliest approach",source:"@site/docs/RAG360/Types of RAG/Naive RAG.md",sourceDirName:"RAG360/Types of RAG",slug:"/RAG360/Types of RAG/Naive RAG",permalink:"/docs/RAG360/Types of RAG/Naive RAG",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"ragSidebar",previous:{title:"Overview",permalink:"/docs/RAG360/Types of RAG/Overview"},next:{title:"Advanced RAG",permalink:"/docs/RAG360/Types of RAG/Advanced RAG"}},l={},d=[{value:"1. Data Ingestion",id:"1-data-ingestion",level:3},{value:"2. Retrieval",id:"2-retrieval",level:3},{value:"3. Generation",id:"3-generation",level:3},{value:"Advantages",id:"advantages",level:3},{value:"Disadvantages",id:"disadvantages",level:3},{value:"Conclusion",id:"conclusion",level:3}];function c(e){const n={code:"code",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Naive RAG (Retrieval Augmented Generation) represents the earliest approach\nto combining retrieval and generation tasks, gaining prominence with the rise\nof large language models such as ChatGPT."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["This method employs a straightforward ",(0,s.jsx)(n.code,{children:"Retrieve-Read"})," framework, which\nincludes three main steps:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Data Ingestion"}),"\n",(0,s.jsx)(n.li,{children:"Retrieval"}),"\n",(0,s.jsx)(n.li,{children:"Generation."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"1-data-ingestion",children:"1. Data Ingestion"}),"\n",(0,s.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Factors"}),(0,s.jsx)("th",{children:"Reason"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Data Cleaning and Extraction"})}),(0,s.jsx)("td",{children:"Raw data from various formats like PDF, HTML, Word, and Markdown is cleaned and converted into plain text."})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Chunking"})}),(0,s.jsx)("td",{children:"The text is segmented into smaller, manageable chunks to accommodate the context limitations of language models."})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Vector Encoding"})}),(0,s.jsx)("td",{children:"These chunks are encoded into vector representations using an embedding model and stored in a vector database. This is crucial for efficient similarity searches during the retrieval phase."})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"2-retrieval",children:"2. Retrieval"}),"\n",(0,s.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Factors"}),(0,s.jsx)("th",{children:"Reason"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Query Encoding"})}),(0,s.jsx)("td",{children:"When a user query is received, it is transformed into a vector representation using the same encoding model used during indexing."})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Similarity Computation"})}),(0,s.jsx)("td",{children:"The system computes similarity scores between the query vector and the vectors of chunks in the indexed corpus."})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Top-K Selection"})}),(0,s.jsx)("td",{children:"The top K chunks with the highest similarity scores are retrieved to serve as the expanded context for the prompt."})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"3-generation",children:"3. Generation"}),"\n",(0,s.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Factors"}),(0,s.jsx)("th",{children:"Reason"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Prompt Construction"})}),(0,s.jsx)("td",{children:"The original query and the retrieved documents are synthesized into a coherent prompt."})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("span",{class:"custom-header",children:"Response Generation"})}),(0,s.jsx)("td",{children:"A large language model generates a response based on this prompt. The model can either draw on its inherent parametric knowledge or rely strictly on the retrieved documents. In ongoing dialogues, conversational history can be incorporated to enable effective multi-turn interactions."})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"advantages",children:"Advantages"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simplicity and Accessibility:"})," The Naive RAG approach is straightforward\nand easy to implement, making it accessible for early adopters of\nretrieval-augmented generation techniques. \ud83d\ude80"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Broad Applicability:"})," It can handle a variety of data formats and\nintegrates well with existing language models, making it versatile for\ndifferent use cases. \ud83c\udf0d"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Enhanced Contextualization:"})," By retrieving relevant documents, the model\ncan provide more contextually rich responses than using only its internal\nknowledge. \ud83d\udcda"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"disadvantages",children:"Disadvantages"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Retrieval Challenges:"})," The retrieval phase may struggle with precision and\nrecall, leading to the selection of irrelevant chunks and the omission of\ncrucial information."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Generation Issues"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hallucination:"})," The model might generate content not supported by the\nretrieved context, resulting in inaccuracies."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Irrelevance, Toxicity, and Bias:"})," Responses can suffer from these\nissues, impacting the quality and reliability of the output."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Augmentation Hurdles"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Integration Difficulties"}),": Combining retrieved information with the\ntask at hand can be challenging, often resulting in disjointed or\nincoherent outputs."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Redundancy:"})," Similar information retrieved from multiple sources can\nlead to repetitive responses."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Significance and Relevance:"})," Determining the importance of various\npassages and maintaining stylistic and tonal consistency adds complexity."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Over-Reliance on Retrieved Content:"})," There's a risk that the model\nmight overly depend on the retrieved information, echoing it without\nproviding additional insight or synthesis."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Naive RAG, as an early methodology in retrieval-augmented generation, lays\nthe foundation for more sophisticated approaches."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"While it offers a simple and accessible framework, its limitations highlight\nthe need for ongoing advancements to improve retrieval precision, response\ngeneration quality and effective integration of retrieved information."}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(96540);const t={},r=s.createContext(t);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);
"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[5668],{5878:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var i=t(74848),a=t(28453);const s={},o="Why FineTuning",r={id:"AI360/FineTuning/what llm lacks",title:"Why FineTuning",description:"What LLM lacks?",source:"@site/docs/AI360/FineTuning/what llm lacks.md",sourceDirName:"AI360/FineTuning",slug:"/AI360/FineTuning/what llm lacks",permalink:"/docs/AI360/FineTuning/what llm lacks",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"AI360Sidebar",previous:{title:"Finetuning",permalink:"/docs/category/finetuning"},next:{title:"Fine Tuning Intro",permalink:"/docs/category/fine-tuning-intro"}},l={},d=[{value:"<strong>What LLM lacks?</strong>",id:"what-llm-lacks",level:2},{value:"<strong>Lack of knowledge (Treatment for Corono)</strong>",id:"lack-of-knowledge-treatment-for-corono",level:3},{value:"<strong>Domain specific Knowledge (Automotive industry)</strong>",id:"domain-specific-knowledge-automotive-industry",level:3},{value:"<strong>In-particular style of doing things(Code generation)</strong>",id:"in-particular-style-of-doing-thingscode-generation",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"why-finetuning",children:"Why FineTuning"})}),"\n",(0,i.jsx)(n.h2,{id:"what-llm-lacks",children:(0,i.jsx)(n.strong,{children:"What LLM lacks?"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"They can generate text, answer questions, and assist with creative and analytical tasks. However, LLMs have limitations, particularly when faced with domain-specific knowledge or highly specialized tasks."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"lack-of-knowledge-treatment-for-corono",children:(0,i.jsx)(n.strong,{children:"Lack of knowledge (Treatment for Corono)"})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Large Language Models (LLMs), despite their impressive capabilities, often face challenges when it comes to keeping their knowledge up to date. For instance, consider a situation where a user asks an LLM, such as ChatGPT, about common illnesses like coughs and colds. The model might provide a good answer, but it may lack the crucial things like COVID-19 updates. This is primarily because LLMs are trained on datasets that may not include the latest information, leading to potentially outdated or incomplete responses."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Once the model is trained, its knowledge base is frozen in time, and it cannot automatically incorporate new information. As a result we may receive the outdated result. Which is not accepted, particularly in the medical industry."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"But We can solve this issue by fine tuning existing LLM. Fine-tuning is the process of taking a pre-trained LLM and further training it on a smaller, more specific dataset that contains updated or relevant information. By integrating new data, we can enhance the model's understanding and ensure it remains informed about current events and advances in various fields."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"If we fine-tune the model using recent health guidelines, research findings, and data related to coughs and colds during the COVID-19 era, it can provide users with more accurate and relevant information. Fine-tuning allows the LLM to learn about the latest symptoms, treatment protocols, and public health recommendations, thereby bridging the gap between its static training and the dynamic nature of real-world knowledge."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"domain-specific-knowledge-automotive-industry",children:(0,i.jsx)(n.strong,{children:"Domain specific Knowledge (Automotive industry)"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Imagine a scenario where a customer service chatbot is tasked with assisting automotive technicians and parts suppliers. When a technician queries about the specifications of a particular engine component, the LLM might struggle to deliver the precise details needed. This limitation arises from the general nature of its training data, which typically lacks the in-depth knowledge specific to automotive parts."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"For instance, if a user asks about the compatibility of a specific aftermarket exhaust system with various car models, the LLM may provide a generic overview of exhaust systems without addressing the in-deapth variations of regulations or performance metrics relevant to that particular product. Such a response can lead to confusion and dissatisfaction."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"To address this, we can fine tune the pre-trained-llm with the data from detailed product catalogs, technical specifications, installation manuals, and customer feedback. By doing this, now the model will be more aware of domain specific information."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Now, we can able to create a chatbot that understands the in-depth details of various automotive components and their applications."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Additionally, fine-tuning allows the chatbot to remain current with the latest trends and innovations in the automotive parts industry. As new products and technologies emerge, updating the training dataset ensures that the chatbot continues to provide accurate and relevant information, keeping pace with the rapid changes in the field."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"in-particular-style-of-doing-thingscode-generation",children:(0,i.jsx)(n.strong,{children:"In-particular style of doing things(Code generation)"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Large Language Models (LLMs) are increasingly being utilized to assist developers in generating code; however, they often struggle to produce code that aligns with the specific standards required for a given project."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Consider a scenario in a Python development team that has adopted strict guidelines enforced by tools like mypy for type checking, pydocstyle for docstring conventions, and flake8 for style checks."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"When a developer seeks to generate a function that processes user input, the initial output from the LLM may not meet these standards, leading to potential issues down the line."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Before Fine-Tuning:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def validateInput(data):\n  if data.isdigit():\n      return True \n  return False\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'In this initial output, the function name is not following any standards may be renamed as "validate_input"  also  there are no type hints, and the lack of a docstring makes it difficult for other developers to understand its purpose.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"To address these issue, fine-tuning the LLM presents a viable solution. This process involves retraining the model on a well assembled dataset that emphasizes coding standards aligned with mypy, pydocstyle, and flake8. By providing the model with examples of well-structured code that follows these guidelines."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"After Fine-Tuning:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def validate_input(data: str) -> bool:\n  """Validates if the input is a digit.\n\n    Args: \n\n        data (str): The input data to validate. \n\n    Returns: \n\n        bool: True if the input is a digit, False otherwise. \n\n    """ \n    return data.isdigit() \n'})}),"\n",(0,i.jsxs)(n.ol,{start:"5",children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"After fine-tuning, the LLM produces code that not only works properly but also obeys to the necessary standards."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The revised function gives a clear name, type hints for both the parameter and return type, and gives appropriate  docstring that explains the function\u2019s purpose and usage."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The newly generated code, now meets the expectations set by mypy, pydocstyle, and flake8."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Fine-tuning allows the model to adapt to various project-specific guidelines, whether that involves different naming conventions, documentation practices, or error handling strategies."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The above may also applicable to the scenario like mail generation in the particular format inside the specific company ect...,"}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(96540);const a={},s=i.createContext(a);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);
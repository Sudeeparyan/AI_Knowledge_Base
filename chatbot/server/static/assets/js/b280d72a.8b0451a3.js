"use strict";(self.webpackChunksudeeparyan_knowledgebase=self.webpackChunksudeeparyan_knowledgebase||[]).push([[6928],{87421:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var i=t(74848),s=t(28453);const r={},a=void 0,o={id:"RAG360/Data Ingestion/Chunking/Overview",title:"Overview",description:"What is Chunking ?",source:"@site/docs/RAG360/Data Ingestion/Chunking/Overview.md",sourceDirName:"RAG360/Data Ingestion/Chunking",slug:"/RAG360/Data Ingestion/Chunking/Overview",permalink:"/docs/RAG360/Data Ingestion/Chunking/Overview",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"ragSidebar",previous:{title:"Chunking",permalink:"/docs/category/chunking"},next:{title:"Different Chunking Methods",permalink:"/docs/RAG360/Data Ingestion/Chunking/Different Chunking Methods"}},c={},d=[{value:"What is Chunking ?",id:"what-is-chunking-",level:3},{value:"<strong>Problem Statement</strong>:",id:"problem-statement",level:4},{value:"Advantages",id:"advantages",level:3},{value:"<strong>Advanced Chunking Strategies</strong>",id:"advanced-chunking-strategies",level:4}];function l(e){const n={code:"code",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h3,{id:"what-is-chunking-",children:"What is Chunking ?"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Chunking is the process of breaking down large datasets into smaller,\r\nmanageable pieces during data ingestion, enabling efficient processing,\r\ntransfer, and storage in systems where handling the entire dataset at once\r\nwould be impractical due to size or performance constraints."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["In ",(0,i.jsx)(n.code,{children:"RAG360"}),", chunking plays a vital role in ensuring the smooth and reliable\r\nintake of large data volumes, maintaining system performance, and minimizing\r\nthe risk of overload or pipeline failures."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.h4,{id:"problem-statement",children:[(0,i.jsx)(n.strong,{children:"Problem Statement"}),":"]}),"\n",(0,i.jsx)(n.p,{children:"As data volumes continue to grow, efficiently processing large datasets becomes\r\nchallenging. Without chunking, systems may struggle with memory management,\r\nlonger processing times, and increased risk of data corruption or loss during\r\ntransfers."}),"\n",(0,i.jsx)(n.h3,{id:"advantages",children:"Advantages"}),"\n",(0,i.jsxs)("table",{class:"table-size-for-cloud-services",children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Benefit"}),(0,i.jsx)("th",{children:"Description"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)("span",{class:"custom-header",children:"Resource Management"})}),(0,i.jsx)("td",{children:"More efficient use of memory and processing power as only portions of the dataset are handled at a time."})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)("span",{class:"custom-header",children:"Flexibility"})}),(0,i.jsx)("td",{children:"Allows parallel processing of chunks to speed up data ingestion and analysis."})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)("span",{class:"custom-header",children:"Error Recovery"})}),(0,i.jsx)("td",{children:"Easier to identify and correct errors in specific chunks without reprocessing the entire dataset."})]})]})]}),"\n",(0,i.jsx)(n.h4,{id:"advanced-chunking-strategies",children:(0,i.jsx)(n.strong,{children:"Advanced Chunking Strategies"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"In enhancing the ingestion process for Retrieval Augmented Generation (RAG)\r\ncomponents, implementing sophisticated chunking strategies is essential for\r\nthe efficient handling of textual data."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"A basic RAG pipeline typically employs a fixed chunking strategy, where a\r\npredetermined number of words or characters constitute a single chunk.\r\nHowever, given the complexities of large datasets, several advanced\r\nstrategies have been developed:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Content-Based Chunking:"})," This strategy involves dividing text based on its meaning and sentence structure, using techniques such as part-of-speech tagging or syntactic parsing. This method ensures that the chunks retain the sense and coherence of the text, although it demands additional computational resources and increased algorithmic complexity."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Sentence Chunking:"})," This approach breaks text into complete and grammatically correct sentences using sentence boundary recognition or speech segmentation. While it maintains the unity and completeness of the text, it can produce chunks of varying sizes, resulting in a lack of homogeneity."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Recursive Chunking:"})," This technique splits text into chunks at different hierarchical levels, creating a more flexible and granular structure. Although this offers greater variety in text granularity, it also introduces complexity in managing and indexing these chunks."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Structured and detailed documentation as outlined above ensures clarity and\r\ncomprehensibility for those involved in managing and executing chunking\r\nprocesses within RAG360's data ingestion framework, providing a\r\ncomprehensive understanding of its necessity and implementation."}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(96540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);